<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css"> ol.lst-kix_vr6v4b3g0q3w-0.start{counter-reset:lst-ctn-kix_vr6v4b3g0q3w-0 0}ol.lst-kix_nn3nangboydl-2.start{counter-reset:lst-ctn-kix_nn3nangboydl-2 0}ol.lst-kix_vr6v4b3g0q3w-7.start{counter-reset:lst-ctn-kix_vr6v4b3g0q3w-7 0}.lst-kix_nn3nangboydl-2 > li{counter-increment:lst-ctn-kix_nn3nangboydl-2}.lst-kix_nn3nangboydl-7 > li{counter-increment:lst-ctn-kix_nn3nangboydl-7}.lst-kix_vr6v4b3g0q3w-4 > li{counter-increment:lst-ctn-kix_vr6v4b3g0q3w-4}.lst-kix_r0450u64qbp3-0 > li:before{content:"●  "}.lst-kix_nn3nangboydl-1 > li:before{content:"" counter(lst-ctn-kix_nn3nangboydl-1,lower-latin) ". "}.lst-kix_nn3nangboydl-3 > li:before{content:"" counter(lst-ctn-kix_nn3nangboydl-3,decimal) ". "}ol.lst-kix_vr6v4b3g0q3w-2{list-style-type:none}.lst-kix_r0450u64qbp3-2 > li:before{content:"■  "}ol.lst-kix_vr6v4b3g0q3w-3{list-style-type:none}ol.lst-kix_vr6v4b3g0q3w-0{list-style-type:none}.lst-kix_r0450u64qbp3-3 > li:before{content:"●  "}ol.lst-kix_vr6v4b3g0q3w-1{list-style-type:none}ol.lst-kix_vr6v4b3g0q3w-3.start{counter-reset:lst-ctn-kix_vr6v4b3g0q3w-3 0}.lst-kix_nn3nangboydl-0 > li:before{content:"" counter(lst-ctn-kix_nn3nangboydl-0,decimal) ". "}.lst-kix_nn3nangboydl-1 > li{counter-increment:lst-ctn-kix_nn3nangboydl-1}.lst-kix_nn3nangboydl-4 > li:before{content:"" counter(lst-ctn-kix_nn3nangboydl-4,lower-latin) ". "}.lst-kix_nn3nangboydl-8 > li{counter-increment:lst-ctn-kix_nn3nangboydl-8}.lst-kix_r0450u64qbp3-1 > li:before{content:"○  "}.lst-kix_vr6v4b3g0q3w-8 > li{counter-increment:lst-ctn-kix_vr6v4b3g0q3w-8}.lst-kix_nn3nangboydl-2 > li:before{content:"" counter(lst-ctn-kix_nn3nangboydl-2,lower-roman) ". "}.lst-kix_vr6v4b3g0q3w-2 > li{counter-increment:lst-ctn-kix_vr6v4b3g0q3w-2}.lst-kix_r0450u64qbp3-8 > li:before{content:"■  "}ol.lst-kix_vr6v4b3g0q3w-6.start{counter-reset:lst-ctn-kix_vr6v4b3g0q3w-6 0}ol.lst-kix_nn3nangboydl-1.start{counter-reset:lst-ctn-kix_nn3nangboydl-1 0}.lst-kix_nn3nangboydl-6 > li{counter-increment:lst-ctn-kix_nn3nangboydl-6}.lst-kix_vr6v4b3g0q3w-5 > li{counter-increment:lst-ctn-kix_vr6v4b3g0q3w-5}.lst-kix_r0450u64qbp3-6 > li:before{content:"●  "}.lst-kix_r0450u64qbp3-7 > li:before{content:"○  "}ol.lst-kix_nn3nangboydl-8.start{counter-reset:lst-ctn-kix_nn3nangboydl-8 0}.lst-kix_nn3nangboydl-8 > li:before{content:"" counter(lst-ctn-kix_nn3nangboydl-8,lower-roman) ". "}.lst-kix_r0450u64qbp3-4 > li:before{content:"○  "}.lst-kix_nn3nangboydl-5 > li:before{content:"" counter(lst-ctn-kix_nn3nangboydl-5,lower-roman) ". "}.lst-kix_nn3nangboydl-7 > li:before{content:"" counter(lst-ctn-kix_nn3nangboydl-7,lower-latin) ". "}.lst-kix_r0450u64qbp3-5 > li:before{content:"■  "}.lst-kix_nn3nangboydl-6 > li:before{content:"" counter(lst-ctn-kix_nn3nangboydl-6,decimal) ". "}.lst-kix_vr6v4b3g0q3w-7 > li{counter-increment:lst-ctn-kix_vr6v4b3g0q3w-7}.lst-kix_nn3nangboydl-0 > li{counter-increment:lst-ctn-kix_nn3nangboydl-0}.lst-kix_nn3nangboydl-3 > li{counter-increment:lst-ctn-kix_nn3nangboydl-3}ol.lst-kix_nn3nangboydl-5.start{counter-reset:lst-ctn-kix_nn3nangboydl-5 0}.lst-kix_vr6v4b3g0q3w-8 > li:before{content:"" counter(lst-ctn-kix_vr6v4b3g0q3w-8,lower-roman) ". "}.lst-kix_vr6v4b3g0q3w-7 > li:before{content:"" counter(lst-ctn-kix_vr6v4b3g0q3w-7,lower-latin) ". "}ul.lst-kix_r0450u64qbp3-8{list-style-type:none}ul.lst-kix_r0450u64qbp3-7{list-style-type:none}ol.lst-kix_vr6v4b3g0q3w-5.start{counter-reset:lst-ctn-kix_vr6v4b3g0q3w-5 0}ul.lst-kix_r0450u64qbp3-6{list-style-type:none}ul.lst-kix_r0450u64qbp3-5{list-style-type:none}ul.lst-kix_r0450u64qbp3-4{list-style-type:none}ul.lst-kix_r0450u64qbp3-3{list-style-type:none}ul.lst-kix_r0450u64qbp3-2{list-style-type:none}ul.lst-kix_r0450u64qbp3-1{list-style-type:none}.lst-kix_vr6v4b3g0q3w-1 > li{counter-increment:lst-ctn-kix_vr6v4b3g0q3w-1}.lst-kix_vr6v4b3g0q3w-5 > li:before{content:"" counter(lst-ctn-kix_vr6v4b3g0q3w-5,lower-roman) ". "}ul.lst-kix_r0450u64qbp3-0{list-style-type:none}ol.lst-kix_vr6v4b3g0q3w-2.start{counter-reset:lst-ctn-kix_vr6v4b3g0q3w-2 0}.lst-kix_vr6v4b3g0q3w-6 > li:before{content:"" counter(lst-ctn-kix_vr6v4b3g0q3w-6,decimal) ". "}ol.lst-kix_nn3nangboydl-7.start{counter-reset:lst-ctn-kix_nn3nangboydl-7 0}.lst-kix_vr6v4b3g0q3w-0 > li:before{content:"" counter(lst-ctn-kix_vr6v4b3g0q3w-0,decimal) ". "}.lst-kix_vr6v4b3g0q3w-1 > li:before{content:"" counter(lst-ctn-kix_vr6v4b3g0q3w-1,lower-latin) ". "}ol.lst-kix_nn3nangboydl-4.start{counter-reset:lst-ctn-kix_nn3nangboydl-4 0}.lst-kix_nn3nangboydl-4 > li{counter-increment:lst-ctn-kix_nn3nangboydl-4}.lst-kix_nn3nangboydl-5 > li{counter-increment:lst-ctn-kix_nn3nangboydl-5}.lst-kix_vr6v4b3g0q3w-4 > li:before{content:"" counter(lst-ctn-kix_vr6v4b3g0q3w-4,lower-latin) ". "}ol.lst-kix_vr6v4b3g0q3w-8.start{counter-reset:lst-ctn-kix_vr6v4b3g0q3w-8 0}.lst-kix_vr6v4b3g0q3w-2 > li:before{content:"" counter(lst-ctn-kix_vr6v4b3g0q3w-2,lower-roman) ". "}.lst-kix_vr6v4b3g0q3w-3 > li:before{content:"" counter(lst-ctn-kix_vr6v4b3g0q3w-3,decimal) ". "}ol.lst-kix_vr6v4b3g0q3w-6{list-style-type:none}ol.lst-kix_nn3nangboydl-3.start{counter-reset:lst-ctn-kix_nn3nangboydl-3 0}ol.lst-kix_nn3nangboydl-4{list-style-type:none}ol.lst-kix_nn3nangboydl-6.start{counter-reset:lst-ctn-kix_nn3nangboydl-6 0}ol.lst-kix_vr6v4b3g0q3w-1.start{counter-reset:lst-ctn-kix_vr6v4b3g0q3w-1 0}ol.lst-kix_vr6v4b3g0q3w-7{list-style-type:none}ol.lst-kix_nn3nangboydl-5{list-style-type:none}ol.lst-kix_vr6v4b3g0q3w-4{list-style-type:none}ol.lst-kix_nn3nangboydl-2{list-style-type:none}ol.lst-kix_vr6v4b3g0q3w-5{list-style-type:none}ol.lst-kix_nn3nangboydl-3{list-style-type:none}ol.lst-kix_nn3nangboydl-8{list-style-type:none}ol.lst-kix_vr6v4b3g0q3w-8{list-style-type:none}ol.lst-kix_nn3nangboydl-6{list-style-type:none}ol.lst-kix_nn3nangboydl-7{list-style-type:none}ol.lst-kix_nn3nangboydl-0{list-style-type:none}ol.lst-kix_nn3nangboydl-1{list-style-type:none}.lst-kix_vr6v4b3g0q3w-6 > li{counter-increment:lst-ctn-kix_vr6v4b3g0q3w-6}ol.lst-kix_nn3nangboydl-0.start{counter-reset:lst-ctn-kix_nn3nangboydl-0 0}.lst-kix_vr6v4b3g0q3w-3 > li{counter-increment:lst-ctn-kix_vr6v4b3g0q3w-3}.lst-kix_vr6v4b3g0q3w-0 > li{counter-increment:lst-ctn-kix_vr6v4b3g0q3w-0}ol.lst-kix_vr6v4b3g0q3w-4.start{counter-reset:lst-ctn-kix_vr6v4b3g0q3w-4 0}</style></head><body class="doc-content" style="background-color:#ffffff;padding:72pt 72pt 72pt 72pt;max-width:468pt"><h2 id="h.z50vezvsol1i" style="padding-top:12pt;margin:0;color:#000000;padding-left:0;font-size:16pt;padding-bottom:12pt;line-height:1.15;page-break-after:avoid;font-family:&quot;Arial&quot;;orphans:2;widows:2;text-align:left;padding-right:0"><span style="color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:&quot;Arial&quot;;font-style:normal">Introduction</span></h2><p style="padding-top:12pt;margin:0;color:#000000;padding-left:0;font-size:11pt;padding-bottom:12pt;font-family:&quot;Arial&quot;;line-height:1.15;orphans:2;widows:2;text-align:left;padding-right:0"><span style="color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:&quot;Arial&quot;;font-style:normal">Computer vision plays a vital role in a wide range of applications, including object recognition, image segmentation, and feature extraction. Circle detection is a fundamental task in computer vision, with applications in robotics, medical imaging, and industrial quality control. The Hough Transform algorithm is a powerful technique for detecting circles in grayscale images. In this article, we will delve into the intricacies of the Hough Transform algorithm and explore its workings in circle detection.</span></p><h2 id="h.ws77q0yfii8b" style="padding-top:12pt;margin:0;color:#000000;padding-left:0;font-size:16pt;padding-bottom:12pt;line-height:1.15;page-break-after:avoid;font-family:&quot;Arial&quot;;orphans:2;widows:2;text-align:left;padding-right:0"><span style="color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:&quot;Arial&quot;;font-style:normal">Understanding the Hough Transform</span></h2><p style="padding-top:12pt;margin:0;color:#000000;padding-left:0;font-size:11pt;padding-bottom:12pt;font-family:&quot;Arial&quot;;line-height:1.15;orphans:2;widows:2;text-align:left;padding-right:0"><span style="color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:&quot;Arial&quot;;font-style:normal">The Hough Transform is a feature extraction technique that enables the detection of shapes, such as lines, circles, and ellipses, in digital images. Initially developed for line detection, it has been extended to handle circles as well. The core idea behind the Hough Transform lies in transforming the image space into parameter space, facilitating the detection of specific shapes based on their characteristic patterns.</span></p><h2 id="h.ob4qxlnwo8ej" style="padding-top:12pt;margin:0;color:#000000;padding-left:0;font-size:16pt;padding-bottom:12pt;line-height:1.15;page-break-after:avoid;font-family:&quot;Arial&quot;;orphans:2;widows:2;text-align:left;padding-right:0"><span style="color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:&quot;Arial&quot;;font-style:normal">Circle Detection using the Hough Transform</span></h2><p style="padding-top:12pt;margin:0;color:#000000;padding-left:0;font-size:11pt;padding-bottom:12pt;font-family:&quot;Arial&quot;;line-height:1.15;orphans:2;widows:2;text-align:left;padding-right:0"><span style="color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:&quot;Arial&quot;;font-style:normal">Detecting circles in a grayscale image using the Hough Transform involves the following steps:</span></p><p style="padding-top:12pt;margin:0;color:#000000;padding-left:0;font-size:11pt;padding-bottom:12pt;font-family:&quot;Arial&quot;;line-height:1.15;orphans:2;widows:2;text-align:left;padding-right:0"><span style="font-weight:700">Step 1</span><span style="color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:&quot;Arial&quot;;font-style:normal">: Preprocessing Convert the input grayscale image into a binary image using appropriate thresholding techniques. This simplifies the circle detection process by reducing the complexity of the input image.</span></p><p style="padding-top:12pt;margin:0;color:#000000;padding-left:0;font-size:11pt;padding-bottom:12pt;font-family:&quot;Arial&quot;;line-height:1.15;orphans:2;widows:2;text-align:left;padding-right:0"><span style="font-weight:700">Step 2</span><span style="color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:&quot;Arial&quot;;font-style:normal">: Edge Detection Apply an edge detection algorithm, such as the Canny edge detector, to identify edges in the binary image. Edges are crucial for circle detection as they represent transitions between different intensity levels, which often correspond to the boundaries of objects, including circles.</span></p><p style="padding-top:12pt;margin:0;color:#000000;padding-left:0;font-size:11pt;padding-bottom:12pt;font-family:&quot;Arial&quot;;line-height:1.15;orphans:2;widows:2;text-align:left;padding-right:0"><span style="font-weight:700">Step 3</span><span style="color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:&quot;Arial&quot;;font-style:normal">: Hough Space Accumulation Create an accumulator array, often referred to as the Hough space, to store the voting information for potential circles. The dimensions of this accumulator array correspond to the radius and center coordinates of the circles being detected.</span></p><p style="padding-top:12pt;margin:0;color:#000000;padding-left:0;font-size:11pt;padding-bottom:12pt;font-family:&quot;Arial&quot;;line-height:1.15;orphans:2;widows:2;text-align:left;padding-right:0"><span style="font-weight:700">Step 4</span><span style="color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:&quot;Arial&quot;;font-style:normal">: Voting for every edge pixel in the binary image, compute all possible circles that could pass through that pixel. Increment the corresponding accumulator cells in the Hough space to vote for the circles that have overlapping parameters.</span></p><p style="padding-top:12pt;margin:0;color:#000000;padding-left:0;font-size:11pt;padding-bottom:12pt;font-family:&quot;Arial&quot;;line-height:1.15;orphans:2;widows:2;text-align:left;padding-right:0"><span style="font-weight:700">Step 5</span><span style="color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:&quot;Arial&quot;;font-style:normal">: Thresholding and Circle Extraction After the voting process, examine the accumulator array and identify the cells with the highest number of votes. These cells correspond to the potential circles present in the image. By setting a suitable threshold, we can filter out weaker circle candidates.</span></p><p style="padding-top:12pt;margin:0;color:#000000;padding-left:0;font-size:11pt;padding-bottom:12pt;font-family:&quot;Arial&quot;;line-height:1.15;orphans:2;widows:2;text-align:left;padding-right:0"><span style="font-weight:700">Step 6</span><span style="color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:&quot;Arial&quot;;font-style:normal">: Circle Parameter Estimation Retrieve the center coordinates and radii of the circles based on the cells with the highest votes. These parameters represent the estimated circles in the original image.</span></p><p style="padding-top:12pt;margin:0;color:#000000;padding-left:0;font-size:11pt;padding-bottom:12pt;font-family:&quot;Arial&quot;;line-height:1.15;orphans:2;widows:2;text-align:left;padding-right:0"><span style="font-weight:700">Step 7</span><span style="color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:&quot;Arial&quot;;font-style:normal">: Visualization Finally, overlay the detected circles on the original grayscale image to visualize the circle detection results.</span></p><h2 id="h.g9r4nc4zbefj" style="padding-top:12pt;margin:0;color:#000000;padding-left:0;font-size:16pt;padding-bottom:12pt;line-height:1.15;page-break-after:avoid;font-family:&quot;Arial&quot;;orphans:2;widows:2;text-align:left;padding-right:0"><span style="color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:&quot;Arial&quot;;font-style:normal">Benefits and Limitations of the Hough Transform Algorithm</span></h2><p style="padding-top:12pt;margin:0;color:#000000;padding-left:0;font-size:11pt;padding-bottom:12pt;font-family:&quot;Arial&quot;;line-height:1.15;orphans:2;widows:2;text-align:left;padding-right:0"><span style="color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:&quot;Arial&quot;;font-style:normal">The Hough Transform algorithm offers several advantages for circle detection:</span></p><ol class="lst-kix_vr6v4b3g0q3w-0 start" start="1" style="padding:0;margin:0"><li style="padding-top:12pt;color:#000000;padding-left:0pt;font-size:11pt;padding-bottom:12pt;line-height:1.15;margin-right:0;margin-left:36pt;font-family:&quot;Arial&quot;;margin-top:0;orphans:2;margin-bottom:0;widows:2;text-align:left;padding-right:0"><span style="font-weight:700">Robustness</span><span style="color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:&quot;Arial&quot;;font-style:normal">: The Hough Transform is capable of detecting circles even in the presence of noise, occlusions, and partial circles.</span></li><li style="padding-top:12pt;color:#000000;padding-left:0pt;font-size:11pt;padding-bottom:12pt;line-height:1.15;margin-right:0;margin-left:36pt;font-family:&quot;Arial&quot;;margin-top:0;orphans:2;margin-bottom:0;widows:2;text-align:left;padding-right:0"><span style="font-weight:700">Parameterization</span><span style="color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:&quot;Arial&quot;;font-style:normal">: The algorithm provides a parameterized representation of the detected circles, making it easier to analyze and extract relevant information.</span></li></ol><p style="padding-top:12pt;margin:0;color:#000000;padding-left:0;font-size:11pt;padding-bottom:12pt;font-family:&quot;Arial&quot;;line-height:1.15;orphans:2;widows:2;text-align:left;padding-right:0"><span style="color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:&quot;Arial&quot;;font-style:normal">However, the Hough Transform algorithm also has certain limitations:</span></p><ol class="lst-kix_nn3nangboydl-0 start" start="1" style="padding:0;margin:0"><li style="padding-top:12pt;color:#000000;padding-left:0pt;font-size:11pt;padding-bottom:12pt;line-height:1.15;margin-right:0;margin-left:36pt;font-family:&quot;Arial&quot;;margin-top:0;orphans:2;margin-bottom:0;widows:2;text-align:left;padding-right:0"><span style="font-weight:700">Computational Complexity</span><span style="color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:&quot;Arial&quot;;font-style:normal">: The Hough Transform can be computationally expensive, particularly for large images or images with high resolution. Various optimization techniques, such as the use of an accumulator matrix, can help mitigate this issue.</span></li><li style="padding-top:12pt;color:#000000;padding-left:0pt;font-size:11pt;padding-bottom:12pt;line-height:1.15;margin-right:0;margin-left:36pt;font-family:&quot;Arial&quot;;margin-top:0;orphans:2;margin-bottom:0;widows:2;text-align:left;padding-right:0"><span style="font-weight:700">Limited to Defined Shape</span><span style="color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:&quot;Arial&quot;;font-style:normal">: The Hough Transform assumes a predefined shape model (e.g., a circle) and may not work effectively for detecting circles with varying radii or non-circular shapes.</span></li></ol><h2 id="h.shoa9er7dj1" style="padding-top:12pt;margin:0;color:#000000;padding-left:0;font-size:16pt;padding-bottom:12pt;line-height:1.15;page-break-after:avoid;font-family:&quot;Arial&quot;;orphans:2;widows:2;text-align:left;padding-right:0"><span style="color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:&quot;Arial&quot;;font-style:normal">Conclusion</span></h2><p style="padding-top:12pt;margin:0;color:#000000;padding-left:0;font-size:11pt;padding-bottom:12pt;font-family:&quot;Arial&quot;;line-height:1.15;orphans:2;widows:2;text-align:left;padding-right:0"><span style="color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:&quot;Arial&quot;;font-style:normal">The Hough Transform algorithm has proven to be a valuable tool for circle detection in grayscale images. By leveraging the power of parameter space and voting, it enables the identification of circular patterns in images, opening up possibilities for numerous applications. While the algorithm has limitations, ongoing research and advancements in computer vision continue to enhance its effectiveness and broaden its scope for shape detection tasks.</span></p><h2 id="h.lukngty984rz" style="padding-top:12pt;margin:0;color:#000000;padding-left:0;font-size:16pt;padding-bottom:12pt;line-height:1.15;page-break-after:avoid;font-family:&quot;Arial&quot;;orphans:2;widows:2;text-align:left;padding-right:0"><span style="color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:&quot;Arial&quot;;font-style:normal">References</span></h2><ul class="lst-kix_r0450u64qbp3-0 start" style="padding:0;margin:0"><li style="padding-top:12pt;color:#000000;padding-left:0pt;font-size:11pt;padding-bottom:12pt;line-height:1.15;margin-right:0;margin-left:36pt;font-family:&quot;Arial&quot;;margin-top:0;orphans:2;margin-bottom:0;widows:2;text-align:left;padding-right:0"><span style="color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:&quot;Arial&quot;;font-style:normal">Duda, R.O., Hart, P.E., &amp; Stork, D.G. (2001). Pattern Classification (2nd ed.). Wiley-Interscience.</span></li><li style="padding-top:12pt;color:#000000;padding-left:0pt;font-size:11pt;padding-bottom:12pt;line-height:1.15;margin-right:0;margin-left:36pt;font-family:&quot;Arial&quot;;margin-top:0;orphans:2;margin-bottom:0;widows:2;text-align:left;padding-right:0"><span style="color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:&quot;Arial&quot;;font-style:normal">Ballard, D.H. (1981). Generalizing the Hough Transform to Detect Arbitrary Shapes. Pattern Recognition, 13(2), 111-122.</span></li><li style="padding-top:12pt;color:#000000;padding-left:0pt;font-size:11pt;padding-bottom:12pt;line-height:1.15;margin-right:0;margin-left:36pt;font-family:&quot;Arial&quot;;margin-top:0;orphans:2;margin-bottom:0;widows:2;text-align:left;padding-right:0"><span>Hough transform. Retrieved June 18, 2023, from </span><span style="text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline"><a href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Hough_transform&amp;sa=D&amp;source=editors&amp;ust=1689226814703910&amp;usg=AOvVaw32CLZJIXnhiNVXZ5gFC6Vl" style="color:inherit;text-decoration:inherit">Hough transform - Wikipedia</a></span></li></ul><hr><p style="padding-top:12pt;margin:0;color:#000000;padding-left:0;font-size:11pt;padding-bottom:12pt;line-height:1.15;font-family:&quot;Arial&quot;;orphans:2;widows:2;height:11pt;text-align:left;padding-right:0"><span style="color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:&quot;Arial&quot;;font-style:normal"></span></p><p style="padding-top:12pt;margin:0;color:#000000;padding-left:0;font-size:11pt;padding-bottom:12pt;font-family:&quot;Arial&quot;;line-height:1.15;orphans:2;widows:2;text-align:left;padding-right:0"><span>Co-authored by GPT-3.5</span></p></body></html>